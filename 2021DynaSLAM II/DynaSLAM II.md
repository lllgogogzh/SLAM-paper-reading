# DynaSLAM II

## 摘要

​		场景刚性的假设在视觉 SLAM 算法中很常见。但是，它限制了它们在人口稠密的现实世界环境中的适用性。此外，包括自动驾驶、多机器人协作和增强/虚拟现实在内的大多数场景都需要环境的明确运动信息来帮助决策和场景理解。我们在本文中介绍了 DynaSLAM II，这是一种用于双目和 RGB-D 配置的视觉 SLAM 系统，它紧密集成了多对象跟踪能力。DynaSLAM II 利用实例语义分割和 ORB 特征来跟踪动态对象。静态场景和动态对象的结构与相机和移动代理的轨迹一起在新的捆绑调整建议中进行了优化。对象的 3D 边界框也在固定的时间窗口内进行估计和松散优化。我们证明了跟踪动态对象不仅为场景理解提供了丰富的线索，而且有利于相机跟踪。

## 方法

### B. Objects Data Association

​	检测出动态物体：使用语义分割。再判断特征点是否在物体内，如果物体掩模内有很多邻近的关键点，则创建一个Objects。

​	接下来，动态特征以两种不同的方式与来自本地地图的动态点相关联：（a）如果地图对象的速度已知，则假设帧间恒速运动通过重投影搜索匹配项，（b） 如果对象速度未初始化或在 (a) 之后没有找到足够的匹配项，我们将在连续帧中蛮力匹配限制为属于其中最重叠实例的那些特征。

​	鉴于跟踪移动对象的任务在 SLAM 之上的额外复杂性和主要是额外数量的参数，保持该数量尽可能减少以保持实时性能非常重要。 像通常的动态 SLAM 实现一样，通过形成独立的点云将动态点建模为重复的 3D 点会导致大量参数。